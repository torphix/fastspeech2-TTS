checkpoint_path:
trainer:
  devices: 1
  max_epochs: 30
  min_epochs: 30
  auto_lr_find: True
  default_root_dir: checkpoints
  # auto_scale_batch_size: "binsearch"
  check_val_every_n_epoch: 1
  accelerator: "gpu"
  # Load checkpoint from here
  gradient_clip_val: 
  gradient_clip_algorithm: "value"
  accumulate_grad_batches: 4
optimizer:
  lr: 2.0e-4
  betas: [0.9,0.99]
scheduler:
  step_size: 1
  gamma: 0.95 # Multiple to reduce LR by each step
  
dataloader:
  batch_size: 4
  num_workers: 2
  shuffle: True
  pin_memory: False
  split: [99, 1]
